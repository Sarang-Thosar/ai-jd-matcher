{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41318a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESUME TEXT:\n",
      "\n",
      "I am a Data Scientist with 3.5 years of experience.\n",
      "I have worked as Data Analyst and Data Engineer.\n",
      "Skills include Python, SQL, Machine Learning, Deep Learning, AWS.\n",
      "I have experience with data pipelines, model building and deployment.\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "JOB DESCRIPTION TEXT:\n",
      "\n",
      "We are looking for a Data Scientist.\n",
      "Required skills: Python, SQL, Machine Learning.\n",
      "Experience in Deep Learning and cloud platforms like AWS is preferred.\n",
      "Candidate should have experience in end-to-end model deployment.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read resume\n",
    "with open(\"../data/resume.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    resume_text = f.read()\n",
    "\n",
    "# Read job description\n",
    "with open(\"../data/jd.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    jd_text = f.read()\n",
    "\n",
    "print(\"RESUME TEXT:\\n\")\n",
    "print(resume_text)\n",
    "\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "print(\"JOB DESCRIPTION TEXT:\\n\")\n",
    "print(jd_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5c0de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEAN RESUME:\n",
      "\n",
      "i am a data scientist with 35 years of experience i have worked as data analyst and data engineer skills include python sql machine learning deep learning aws i have experience with data pipelines model building and deployment\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "CLEAN JD:\n",
      "\n",
      "we are looking for a data scientist required skills python sql machine learning experience in deep learning and cloud platforms like aws is preferred candidate should have experience in endtoend model deployment\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # 1. Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Remove punctuation and special characters\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
    "    \n",
    "    # 3. Remove extra spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "clean_resume = clean_text(resume_text)\n",
    "clean_jd = clean_text(jd_text)\n",
    "\n",
    "print(\"CLEAN RESUME:\\n\")\n",
    "print(clean_resume)\n",
    "\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "print(\"CLEAN JD:\\n\")\n",
    "print(clean_jd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0120eb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume embedding length: 384\n",
      "JD embedding length: 384\n",
      "\n",
      "First 10 numbers of resume embedding:\n",
      " [-0.02466562 -0.04261731  0.04265124  0.0743174  -0.06062206 -0.10230157\n",
      " -0.01304876 -0.02319215 -0.09969875 -0.03157195]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load model (downloads once)\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Generate embeddings\n",
    "resume_embedding = model.encode(clean_resume)\n",
    "jd_embedding = model.encode(clean_jd)\n",
    "\n",
    "print(\"Resume embedding length:\", len(resume_embedding))\n",
    "print(\"JD embedding length:\", len(jd_embedding))\n",
    "\n",
    "print(\"\\nFirst 10 numbers of resume embedding:\\n\", resume_embedding[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c40158b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume–JD Match Percentage: 75.83 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Reshape embeddings (required by sklearn)\n",
    "resume_vec = resume_embedding.reshape(1, -1)\n",
    "jd_vec = jd_embedding.reshape(1, -1)\n",
    "\n",
    "# Calculate similarity\n",
    "similarity_score = cosine_similarity(resume_vec, jd_vec)[0][0]\n",
    "\n",
    "# Convert to percentage\n",
    "match_percentage = round(similarity_score * 100, 2)\n",
    "\n",
    "print(\"Resume–JD Match Percentage:\", match_percentage, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "312ec822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an AI hiring assistant.\n",
      "\n",
      "Resume:\n",
      "i am a data scientist with 35 years of experience i have worked as data analyst and data engineer skills include python sql machine learning deep learning aws i have experience with data pipelines model building and deployment\n",
      "\n",
      "Job Description:\n",
      "we are looking for a data scientist required skills python sql machine learning experience in deep learning and cloud platforms like aws is preferred candidate should have experience in endtoend model deployment\n",
      "\n",
      "The resume matches the job description with a score of 75.83000183105469%.\n",
      "\n",
      "Explain the match in simple bullet points:\n",
      "1. Key matching skills\n",
      "2. Missing or weak skills\n",
      "3. Overall summary in 2 lines\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_explanation_prompt(resume_text, jd_text, match_percentage):\n",
    "    prompt = f\"\"\"\n",
    "You are an AI hiring assistant.\n",
    "\n",
    "Resume:\n",
    "{resume_text}\n",
    "\n",
    "Job Description:\n",
    "{jd_text}\n",
    "\n",
    "The resume matches the job description with a score of {match_percentage}%.\n",
    "\n",
    "Explain the match in simple bullet points:\n",
    "1. Key matching skills\n",
    "2. Missing or weak skills\n",
    "3. Overall summary in 2 lines\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "match_percentage_rounded = round(match_percentage, 2)\n",
    "\n",
    "prompt_text = generate_explanation_prompt(clean_resume, clean_jd, match_percentage_rounded)\n",
    "print(prompt_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc6a327",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Set API key (temporary method)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# os.environ[\"OPENAI_API_KEY\"] = \"your_api_key_here\"\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_llm_explanation\u001b[39m(prompt):\n\u001b[0;32m     10\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     11\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m\n\u001b[0;32m     17\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\openai\\_client.py:137\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    135\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m     )\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Set API key (temporary method)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your_api_key_here\"\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def get_llm_explanation(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI hiring assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Call LLM\n",
    "# explanation = get_llm_explanation(prompt_text)\n",
    "# print(explanation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4335c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an experienced technical interviewer.\n",
      "\n",
      "Resume:\n",
      "i am a data scientist with 35 years of experience i have worked as data analyst and data engineer skills include python sql machine learning deep learning aws i have experience with data pipelines model building and deployment\n",
      "\n",
      "Job Description:\n",
      "we are looking for a data scientist required skills python sql machine learning experience in deep learning and cloud platforms like aws is preferred candidate should have experience in endtoend model deployment\n",
      "\n",
      "Generate interview questions in the following format:\n",
      "\n",
      "Technical Questions:\n",
      "- Question 1\n",
      "- Question 2\n",
      "- Question 3\n",
      "\n",
      "Scenario-Based Questions:\n",
      "- Question 1\n",
      "- Question 2\n",
      "\n",
      "Skill Gap Questions:\n",
      "- Question 1\n",
      "- Question 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_interview_questions_prompt(resume_text, jd_text):\n",
    "    prompt = f\"\"\"\n",
    "You are an experienced technical interviewer.\n",
    "\n",
    "Resume:\n",
    "{resume_text}\n",
    "\n",
    "Job Description:\n",
    "{jd_text}\n",
    "\n",
    "Generate interview questions in the following format:\n",
    "\n",
    "Technical Questions:\n",
    "- Question 1\n",
    "- Question 2\n",
    "- Question 3\n",
    "\n",
    "Scenario-Based Questions:\n",
    "- Question 1\n",
    "- Question 2\n",
    "\n",
    "Skill Gap Questions:\n",
    "- Question 1\n",
    "- Question 2\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "question_prompt = generate_interview_questions_prompt(clean_resume, clean_jd)\n",
    "print(question_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4adc807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.4\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d018c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interview_questions = get_llm_response(question_prompt)\n",
    "# print(interview_questions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
